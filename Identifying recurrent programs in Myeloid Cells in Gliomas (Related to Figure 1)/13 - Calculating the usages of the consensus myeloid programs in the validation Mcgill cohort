####### After we obtained the spectra for all consensus programs in Step 12, we placed the values in a data frame "consensus_spectra.txt" ######

############## Filter the Mcgill Cohort Matrix to include only non-doublet myeloid cells and genes that were used for Round 2 cNMF in the discovery cohorts #######

############## Inside R ################################
library(dplyr)
library(Seurat)
options(bitmapType='cairo')
options(future.globals.maxSize = 8000 * 1024^2)

Matrix <- GetAssayData(Tumors.combined, slot = "counts")

Genes <- read.table("union_filtered_Variable.txt", sep="\t", head=TRUE, row.names=1)

Genes2 <- rownames(Genes)

Matrix2 <- Matrix[rownames(Matrix) %in% Genes2,]

write.table(t(as.matrix(Matrix2)), file="./OPK_10X_Raw_Counts_Variable_for_Myeloid_cNMF.txt", sep="\t", col.names=NA, quote=FALSE)


dim(Matrix2) ######### to find out the number for --numgenes below #################

q()

##################################### Exit R ###########################################
conda activate cnmf_env

cnmf prepare --output-dir ./Calculate_Usage_Myeloid/ --name Calculate_Usage_Myeloid -c OPK_10X_Raw_Counts_Variable_for_Myeloid_cNMF.txt -k 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 --n-iter 500 --total-workers 1 --seed 14 --numgenes 2278;

python;

################################## Inside Python #################################

import sklearn
import sklearn.decomposition
from sklearn.decomposition import non_negative_factorization
import numpy as np
import scanpy as sc
import csv
import scipy
import pandas as pd
 

H = pd.read_table("consensus_spectra.txt", sep="\t", index_col=0)

H2 = H.T

X = sc.read_h5ad('Calculate_Usage_Myeloid/Calculate_Usage_Myeloid/cnmf_tmp/Calculate_Usage_Myeloid.norm_counts.h5ad')

X2 = X.X.toarray()

X3 = pd.DataFrame(data=X2, columns = X.var_names , index = X.obs.index)

H3 = H2.filter(items = X3.columns)

H4 = H3.to_numpy()

X5 = X2.astype(np.float64)

test = sklearn.decomposition.non_negative_factorization(X5, W=None, H=H4, n_components= 14, init='random', update_H=False, solver='cd', beta_loss='frobenius', tol=0.0001, max_iter=1000, alpha=0.0, alpha_W=0.0, alpha_H='same', l1_ratio=0.0, regularization=None, random_state=None, verbose=0, shuffle=False)

test2 = list(test)

pd.DataFrame(test2[0], columns= H.columns, index=X.obs.index).to_csv(path_or_buf="./OPK_10X_Myeloid_Programs_Usage.txt", sep="\t", quoting=csv.QUOTE_NONE)

############ The output "OPK_10X_Myeloid_Programs_Usage.txt" contains the usage values of all cells which can be then normalized to percentages (each row (cell) the values of the usages should be converted to percentages so that the sums of the program usages will be always 100 in every cell ##############
